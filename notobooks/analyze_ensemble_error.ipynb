{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename):\n",
    "    data = pd.read_table(filename, sep='\\t', encoding='utf-8',\n",
    "                     names=['qid','truth', 'prediction'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_table('Quora_question_pair_partition/test.tsv', sep='\\t', encoding='utf-8',\n",
    "                     names=['is_duplicate','question1', 'question2', 'qid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5k = read_dataset('/Users/andrada/Thesis_notebooks/ensemble/predictions.quora.ensemble.reverse_5k.tsv')\n",
    "df_10k = read_dataset('/Users/andrada/Thesis_notebooks/ensemble/predictions.quora.ensemble.reverse_10k.tsv')\n",
    "df_15k = read_dataset('/Users/andrada/Thesis_notebooks/ensemble/predictions.quora.ensemble.reverse_15k.tsv')\n",
    "df_20k = read_dataset('/Users/andrada/Thesis_notebooks/ensemble/predictions.quora.ensemble.reverse_20k.tsv')\n",
    "df_25k = read_dataset('/Users/andrada/Thesis_notebooks/ensemble/predictions.quora.ensemble.reverse_25k.tsv')\n",
    "df_30k = read_dataset('/Users/andrada/Thesis_notebooks/ensemble/predictions.quora.ensemble.reverse_30k.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "def word_match_share(row):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['q1_lemma']).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['q2_lemma']).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return round(R,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, name):\n",
    "    column = 'prediction_' + name\n",
    "    df[column] = df['prediction'].apply(lambda x: x.replace('[',''))\n",
    "    df[column] = df[column].apply(lambda x: x.replace(']',''))\n",
    "    df[column] = df[column].apply(pd.to_numeric)\n",
    "    return df\n",
    "\n",
    "def errors(df,name):\n",
    "    column = 'prediction_' + name\n",
    "    new_col = 'label_'+ name\n",
    "    df[new_col] = df[column].apply(lambda x: int(x > 0.5))\n",
    "    return df\n",
    "\n",
    "def prepare_df(df, name):\n",
    "    df = preprocess(df, name)\n",
    "    df = errors(df,name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_5k = prepare_df(df_5k, '5k')\n",
    "errors_10k = prepare_df(df_10k, '10k')\n",
    "errors_15k = prepare_df(df_15k, '15k')\n",
    "errors_20k = prepare_df(df_20k, '20k')\n",
    "errors_25k = prepare_df(df_25k, '25k')\n",
    "errors_30k = prepare_df(df_30k, '30k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [df_test, errors_5k, errors_10k, errors_15k, errors_20k, errors_25k, errors_30k]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['qid'], how='inner'), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns=['truth_x', 'truth_y', 'prediction_x', 'prediction_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['q1_lemma'] = df_merged['question1'].apply(lemmatize_text)\n",
    "df_merged['q2_lemma'] = df_merged['question2'].apply(lemmatize_text)\n",
    "df_merged['word_overlap'] = df_merged.apply( word_match_share, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (df_merged['is_duplicate'] != df_merged['label_5k'])\n",
    "mask2 = (df_merged['is_duplicate'] != df_merged['label_10k'])\n",
    "mask3 = (df_merged['is_duplicate'] != df_merged['label_15k'])\n",
    "mask4 = (df_merged['is_duplicate'] != df_merged['label_20k'])\n",
    "mask5 = (df_merged['is_duplicate'] != df_merged['label_25k'])\n",
    "mask6 = (df_merged['is_duplicate'] != df_merged['label_30k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6456360708534616, 0.17936480105663222)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_errors = df_merged[mask1 & mask2 & mask3 & mask4 & mask5 & mask6]\n",
    "df_errors['word_overlap'].mean(), df_errors['word_overlap'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction_5k</th>\n",
       "      <th>label_5k</th>\n",
       "      <th>prediction_10k</th>\n",
       "      <th>label_10k</th>\n",
       "      <th>prediction_15k</th>\n",
       "      <th>label_15k</th>\n",
       "      <th>prediction_20k</th>\n",
       "      <th>label_20k</th>\n",
       "      <th>prediction_25k</th>\n",
       "      <th>label_25k</th>\n",
       "      <th>prediction_30k</th>\n",
       "      <th>label_30k</th>\n",
       "      <th>q1_lemma</th>\n",
       "      <th>q2_lemma</th>\n",
       "      <th>word_overlap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_duplicate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              question1  question2  qid  prediction_5k  label_5k  \\\n",
       "is_duplicate                                                       \n",
       "0                   429        429  429            429       429   \n",
       "1                   192        192  192            192       192   \n",
       "\n",
       "              prediction_10k  label_10k  prediction_15k  label_15k  \\\n",
       "is_duplicate                                                         \n",
       "0                        429        429             429        429   \n",
       "1                        192        192             192        192   \n",
       "\n",
       "              prediction_20k  label_20k  prediction_25k  label_25k  \\\n",
       "is_duplicate                                                         \n",
       "0                        429        429             429        429   \n",
       "1                        192        192             192        192   \n",
       "\n",
       "              prediction_30k  label_30k  q1_lemma  q2_lemma  word_overlap  \n",
       "is_duplicate                                                               \n",
       "0                        429        429       429       429           429  \n",
       "1                        192        192       192       192           192  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_errors.groupby('is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193433931484515"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[mask1]['word_overlap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6201648351648362"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[mask2]['word_overlap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6246259124087599"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[mask3]['word_overlap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6254375569735656"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[mask4]['word_overlap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6226815050344467"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[mask5]['word_overlap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6270961718020562"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[mask6]['word_overlap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
